{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 17:03:40.346389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports, hyperparams & data prep (real + synth), normalization, poly‐feature cache\n",
    "import random, re, math\n",
    "import numpy as np, pandas as pd\n",
    "import sympy as sp\n",
    "import tensorflow as tf, mpmath as mp\n",
    "from functools import lru_cache\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, TextVectorization, Embedding, LSTM,\n",
    "    Dense, Concatenate, Lambda\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "\n",
    "x = sp.symbols('x')\n",
    "SEQ_LEN, BATCH, LR, EPOCHS, INT_TOL = 64, 64, 1e-4, 20, 1e-6\n",
    "\n",
    "# load real data\n",
    "df_real = pd.read_csv(\"functions2.csv\", header=None,\n",
    "    names=[\"function\",\"lower\",\"upper\",\"true_raw\"])\n",
    "df_real[\"lower\"]    = pd.to_numeric(df_real[\"lower\"], errors=\"coerce\")\n",
    "df_real[\"upper\"]    = pd.to_numeric(df_real[\"upper\"], errors=\"coerce\")\n",
    "df_real[\"true_raw\"] = pd.to_numeric(df_real[\"true_raw\"], errors=\"coerce\")\n",
    "df_real.dropna(subset=[\"lower\",\"upper\",\"true_raw\"], inplace=True)\n",
    "df_real.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# synthetic polys\n",
    "@lru_cache(None)\n",
    "def make_random_poly(d):\n",
    "    cs = [random.uniform(-5,5) for _ in range(d+1)]\n",
    "    return sum(c*x**i for i,c in enumerate(cs))\n",
    "\n",
    "@lru_cache(None)\n",
    "def integrate_sympy(s,a,b):\n",
    "    e = sp.sympify(s.replace('^','**').replace('ln(','log('))\n",
    "    return float(sp.integrate(e,(x,a,b)))\n",
    "\n",
    "rows = []\n",
    "for _ in range(5000):\n",
    "    d = random.randint(1,5)\n",
    "    e = make_random_poly(d)\n",
    "    a, b = random.uniform(-3,0), random.uniform(0,3)\n",
    "    s = integrate_sympy(str(e).replace('**','^'),a,b)\n",
    "    rows.append({\n",
    "        \"function\": str(e).replace('**','^'),\n",
    "        \"lower\":    a,\n",
    "        \"upper\":    b,\n",
    "        \"true_raw\": s\n",
    "    })\n",
    "df_synth = pd.DataFrame(rows)\n",
    "\n",
    "# combine, shuffle & norm\n",
    "df = pd.concat([df_real,df_synth], axis=0).sample(frac=1,random_state=42)\n",
    "y_mean, y_std = df[\"true_raw\"].mean(), df[\"true_raw\"].std()\n",
    "df[\"y_norm\"]  = (df[\"true_raw\"] - y_mean)/y_std\n",
    "l_mean, l_std = df[\"lower\"].mean(), df[\"lower\"].std()\n",
    "u_mean, u_std = df[\"upper\"].mean(), df[\"upper\"].std()\n",
    "df[\"lower_n\"] = (df[\"lower\"] - l_mean)/l_std\n",
    "df[\"upper_n\"] = (df[\"upper\"] - u_mean)/u_std\n",
    "\n",
    "@lru_cache(None)\n",
    "def poly_feats_cached(s):\n",
    "    try:\n",
    "        e = sp.sympify(s.replace('^','**').replace('ln(','log('))\n",
    "        p = sp.Poly(e, x)\n",
    "        return tuple(float(p.coeff_monomial(x**i)) for i in range(6))\n",
    "    except:\n",
    "        return (0.0,)*6\n",
    "\n",
    "df[\"poly_feats\"] = df[\"function\"].apply(poly_feats_cached)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(\"Total samples:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Text‐vectorizer + dataset builder (handles '^'→'**', 'ln('→'log(')\n",
    "vectorizer = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQ_LEN,\n",
    "    standardize=lambda s:\n",
    "      tf.strings.regex_replace(\n",
    "        tf.strings.regex_replace(tf.strings.lower(s),\n",
    "                                 r\"\\^\",\"**\"),\n",
    "                                 r\"ln\\(\",\"log(\"),\n",
    "    split=\"character\"\n",
    ")\n",
    "vectorizer.adapt(train_df[\"function\"].values)\n",
    "\n",
    "def make_ds(ddf, shuffle=True):\n",
    "    X = {\n",
    "      \"func_input\":  ddf[\"function\"].values,\n",
    "      \"lower_input\": ddf[\"lower_n\"].values.astype(np.float32),\n",
    "      \"upper_input\": ddf[\"upper_n\"].values.astype(np.float32),\n",
    "      \"poly_feats\":  np.stack(ddf[\"poly_feats\"].values).astype(np.float32),\n",
    "    }\n",
    "    y = ddf[\"y_norm\"].values.astype(np.float32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X,y))\n",
    "    if shuffle: ds = ds.shuffle(len(ddf))\n",
    "    return ds.batch(BATCH).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(train_df, shuffle=True)\n",
    "val_ds   = make_ds(val_df,   shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Build 3‐branch model (chars → LSTM, bounds, poly‐feats → merge)\n",
    "f_in = Input(shape=(), dtype=tf.string, name=\"func_input\")\n",
    "toks = vectorizer(f_in)\n",
    "toks = Lambda(lambda t: tf.cast(t,tf.int32))(toks)\n",
    "c = Embedding(vectorizer.vocabulary_size(),32,mask_zero=True)(toks)\n",
    "c = LSTM(32)(c)\n",
    "\n",
    "l_in = Input((1,),dtype=tf.float32,name=\"lower_input\")\n",
    "u_in = Input((1,),dtype=tf.float32,name=\"upper_input\")\n",
    "b   = Concatenate()([l_in,u_in])\n",
    "b   = Dense(16,activation=\"relu\")(b)\n",
    "b   = Dense(8, activation=\"relu\")(b)\n",
    "\n",
    "p_in = Input((6,),dtype=tf.float32,name=\"poly_feats\")\n",
    "p   = Dense(32,activation=\"relu\")(p_in)\n",
    "p   = Dense(16,activation=\"relu\")(p)\n",
    "\n",
    "m = Concatenate()([c,b,p])\n",
    "m = Dense(64,activation=\"relu\")(m)\n",
    "m = Dense(32,activation=\"relu\")(m)\n",
    "out = Dense(1,activation=\"linear\",name=\"pred\")(m)\n",
    "\n",
    "model = Model([f_in,l_in,u_in,p_in],out)\n",
    "model.compile(Adam(LR,clipnorm=1.0), \"huber\", metrics=[\"mae\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 207252\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train & evaluate\n",
    "model.fit(train_ds, validation_data=val_ds,\n",
    "          epochs=EPOCHS, callbacks=[TerminateOnNaN()])\n",
    "loss, mae = model.evaluate(val_ds)\n",
    "print(f\"Val Huber={loss:.4f}, MAE(norm)={mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Safe inference → NN, then Sympy/mpmath, then trapezoid\n",
    "def safe_integral(func_str, a, b, tol=INT_TOL):\n",
    "    expr_in = func_str.replace('^','**').replace('ln(','log(')\n",
    "    ln_n = (a - l_mean)/l_std\n",
    "    un_n = (b - u_mean)/u_std\n",
    "    pf   = np.array(poly_feats_cached(func_str),dtype=np.float32)[None]\n",
    "    # NN\n",
    "    fn = np.array([func_str],dtype=object)\n",
    "    rn = model.predict([fn,\n",
    "                        [[ln_n]],\n",
    "                        [[un_n]],\n",
    "                        pf],verbose=0)[0,0]\n",
    "    pn = rn*y_std + y_mean\n",
    "    if not np.isnan(pn) and abs(pn-round(pn))<tol:\n",
    "        return round(pn)\n",
    "    # exact\n",
    "    try:\n",
    "        e = sp.sympify(expr_in)\n",
    "        return float(sp.integrate(e,(x,a,b)))\n",
    "    except:\n",
    "        pass\n",
    "    # numeric\n",
    "    try:\n",
    "        e = sp.sympify(expr_in,convert_xor=True)\n",
    "        fmp = sp.lambdify(x,e,'mpmath')\n",
    "        return float(mp.quad(fmp,[a,b]))\n",
    "    except:\n",
    "        pass\n",
    "    # fallback\n",
    "    safe = re.sub(r'(?<=\\d)(?=[A-Za-z\\(])','*',expr_in)\n",
    "    f = lambda v: eval(safe,{\"x\":v,**math.__dict__})\n",
    "    xs = np.linspace(a,b,2000)\n",
    "    ys = [f(v) for v in xs]\n",
    "    return float(np.trapz(ys,xs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Interactive prompt (fractions in func, ln(), etc. all work)\n",
    "def predict_interactive():\n",
    "    f = input(\"Function (e.g. x^2/(x^3-1)+ln(x)): \")\n",
    "    a = float(input(\"Lower bound: \"))\n",
    "    b = float(input(\"Upper bound: \"))\n",
    "    print(\"Result ≃\", safe_integral(f,a,b))\n",
    "\n",
    "predict_interactive()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
